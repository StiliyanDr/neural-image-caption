{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"neural_image_caption.ipynb","provenance":[{"file_id":"1jJoVuJCo7p5RyAj45E-Z7IHDvFMJ9mRO","timestamp":1629559090251}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6lvlPMI2T3ZR"},"source":["### Mount drive\n","Mount drive to access the dataset and save model checkpoints.  \n","\n","Set `drive_path` to the directory on your drive which contains various resources for training the NIC model, like *data.zip* - an archive with image features. TensorBoard logs and model checkpoints will go into this directory too.   "]},{"cell_type":"code","metadata":{"id":"pz9fy7jANkXA"},"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\")\n","drive_path = \"drive/MyDrive/ML/neural_image_caption\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i99eSjRGUfhh"},"source":["### Install nic\n","Install the **nic** package into the session.  "]},{"cell_type":"code","metadata":{"id":"u28MchmaM8Of"},"source":["!pip install nic"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nRAraToeU4Eq"},"source":["### Extract preprocessed features into the session \n","Preprocessed image features shouldn't take up a lot of disk space so they can be extracted from *data.zip* into the current session. If the entire model needs to be trained or evaluated, images will need to be accessed from Drive, if they fit in there.  "]},{"cell_type":"code","metadata":{"id":"a_Vm9EhSTb5j"},"source":["import os\n","\n","os.environ[\"MSCOCO_DATA_ARCHIVE\"] = os.path.join(drive_path, \"data.zip\")\n","\n","!unzip \"$MSCOCO_DATA_ARCHIVE\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BKIMGpEKVvAG"},"source":["### Define the model\n","Here we define the decoder module of the model.  \n","\n","The features size and vocabulary size can be computed from the preprocessed data so only RNN related parameters should be set (as `rnn_options` below).  "]},{"cell_type":"code","metadata":{"id":"n2RD3WHfNWED"},"source":["import os\n","from pathlib import Path\n","\n","from matplotlib import pyplot as plt\n","import nic\n","import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SVPIkt4dTG9p"},"source":["data_dir = \"data\"\n","rnn_options = nic.RNNOptions(size=512)\n","decoder_name = \"nic-decoder\"\n","\n","decoder = nic.define_decoder_model(\n","    nic.dp.features_size(data_dir),\n","    nic.dp.vocabulary_size(data_dir),\n","    rnn_options,\n","    decoder_name,\n",")\n","tf.keras.utils.plot_model(decoder,\n","                          \"decoder.png\",\n","                          show_shapes=True,\n","                          show_dtype=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D9n0kbRZZzYt"},"source":["decoder.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6VxIGd9vbezP"},"source":["### Train the model\n","We first compile the model or restore one of its checkpoints (with `start_from_scratch = False`). Then we (extra)train the model. When extra training, make sure to set `initial_epoch` to the number of the last completed epoch and **increase** `max_epochs`.  \n","\n","To restore the best model so far, set `restore_best` to `True`. Othewise, the latest checkpoint is restored.  \n","\n","The training algorithm and its related parameters like `decay_patience` and `perplexity_delta` are described below.  "]},{"cell_type":"code","metadata":{"id":"UWGdLMEocYm-"},"source":["start_from_scratch = True\n","\n","learning_rate = 0.00001\n","batch_size = 40\n","buffer_size = 1024\n","\n","learning_rate_decay = 0.9\n","decay_patience = 2\n","perplexity_delta = 0.01\n","min_learning_rate = 0.0\n","early_stop_patience = 2\n","\n","initial_epoch = 0\n","max_epochs = 10\n","shuffle_for_each_epoch = True\n","\n","tensor_board_dir = os.path.join(drive_path, \"tensor_board\")\n","tensor_board_update_freq = 5000\n","\n","restore_best = False\n","checkpoint_freq = \"epoch\"\n","checkpoint_dir = os.path.join(drive_path, \"checkpoints\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AgWAWWSOLwIY"},"source":["Create subdirectories for a training process' TensorBoard logs and checkpoints (if they do not already exist).  "]},{"cell_type":"code","metadata":{"id":"h_FEAoZlMKKZ"},"source":["subdir_name = f\"lr={learning_rate:.6f}_hs={rnn_options.size}\"\n","tensor_board_subdir = os.path.join(tensor_board_dir, subdir_name)\n","checkpoints_subdir = os.path.join(checkpoint_dir, subdir_name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZZM5vCBcxpm4"},"source":["Path(tensor_board_subdir).mkdir(parents=True, exist_ok=True)\n","Path(checkpoints_subdir).mkdir(parents=True, exist_ok=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hjv-CVd1OT-c"},"source":["Now we compile the model or restore a saved model.  "]},{"cell_type":"code","metadata":{"id":"5ALfliTVaJnk"},"source":["if (start_from_scratch):\n","    compiled_decoder = nic.compile_model(\n","        decoder,\n","        learning_rate\n","    )\n","else:\n","    compiled_decoder = nic.restore_model(\n","        checkpoints_subdir,\n","        restore_best\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dgWJEPlMOfQ6"},"source":["Here we train the decoder module of the model for at most `max_epochs` epochs, possibly shuffling the train data prior to each epoch (`shuffle_for_each_epoch`).  \n","\n","The initial learning rate is `learning_rate` if the process is started from scratch; restored models come with their optimizers which include the latest learning rate. If the validation perplexity does not improve with at least `perplexity_delta` for `decay_patience` epochs in a row, the learning rate is reduced my multiplying it with `learning_rate_decay` ($lr = decay * lr$). If `early_stop_patience` learning rate changes still lead to no perplexity improvement (or the loss becomes NaN), the training process is terminated.  \n","\n","TensorBoard logs go to `tensor_board_subdir` with `tensor_board_update_freq` frequency.  \n","\n","Checkpoints (`SavedModel`s) go to `checkpoints_subdir` with `checkpoint_freq` frequency.  \n","\n"]},{"cell_type":"code","metadata":{"id":"t5SaAS1Cdihn"},"source":["history, metrics = nic.train_model(\n","    model=compiled_decoder,\n","    path_to_data=data_dir,\n","    is_decoder_only=True,\n","    batch_size=batch_size,\n","    buffer_size=buffer_size,\n","    tensor_board_dir=tensor_board_subdir,\n","    tensor_board_update_freq=tensor_board_update_freq,\n","    checkpoint_dir=checkpoints_subdir,\n","    checkpoint_freq=checkpoint_freq,\n","    learning_rate_decay=learning_rate_decay,\n","    decay_patience=decay_patience,\n","    perplexity_delta=perplexity_delta,\n","    min_learning_rate=min_learning_rate,\n","    early_stop_patience=early_stop_patience,\n","    max_epochs=max_epochs,\n","    shuffle_for_each_epoch=shuffle_for_each_epoch,\n","    initial_epoch=initial_epoch\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FmJC39leNNYS"},"source":["print(\"Test metrics:\")\n","\n","for name, value in metrics.items():\n","    print(f\"{name}: {value:.4f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Kdjwc3BsYdr"},"source":["### Plots\n","Here we plot the training history and view TensorBoard logs.  "]},{"cell_type":"code","metadata":{"id":"97lmcoWwPkyK"},"source":["def plot(history, metric, title=None):\n","    y = history.history[metric]\n","\n","    if (title is None):\n","        title = metric.capitalize()\n","\n","    plt.plot(y)\n","    plt.xlabel('Epochs')\n","    plt.ylabel(title)\n","    plt.title(f\"{title} plot\")\n","    return plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ty3RsZQqQ2Ow"},"source":["plot(history, \"loss\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"snQ-fwT7O8tr"},"source":["plot(history, \"val_loss\", title=\"Validation loss\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e1JsHNVvRCLf"},"source":["plot(history, \"perplexity\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dxQ8YT_HRIUR"},"source":["plot(history, \"val_perplexity\", title=\"Validation perplexity\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h5VofbuQRPQW"},"source":["plot(history, \"lr\", title=\"Learning rate\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sotTQZrxf-RN"},"source":["Copy the output of the next cell and paste it inside the quotes after `--logdir`.  "]},{"cell_type":"code","metadata":{"id":"u_2J1YixjFoo"},"source":["tensor_board_subdir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OCpAnu7rscjF"},"source":["%load_ext tensorboard\n","%tensorboard --logdir \"\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YLYYWB1i9XiU"},"source":["### Evaluate\n","Here we evaulate the decoder module by computing its [BLEU-4](https://aclanthology.org/P02-1040.pdf) score on test and validation images.  "]},{"cell_type":"code","metadata":{"id":"4Oj_dx_y_LRQ"},"source":["data_types = [\n","    \"test\",\n","    \"val\",\n","]\n","scores = dict()\n","\n","for t in data_types:\n","    scores[t] = nic.bleu_score_of(\n","        compiled_decoder,\n","        is_decoder_only=True,\n","        path_to_data=data_dir,\n","        data_type=t,\n","        batch_size=32,\n","        caption_limit=100\n","    )\n","    print(f\"Model {t} BLEU score: {scores[t]:.2f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OLydRMUIayPQ"},"source":["### Generate captions\n","At this point we can generate captions for images which are not necessarily part of MSCOCO.  \n","\n","We need to set `path_to_images` to a directory storing images to be captioned. The images can be in JPEG and PNG format.  \n","\n","We also need to connect the decoder module with the CNN encoder.  \n","\n"]},{"cell_type":"code","metadata":{"id":"JpBsRsBfTFj4"},"source":["from PIL import Image\n","\n","path_to_images = os.path.join(drive_path, \"images\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ORQfLesQSTmS"},"source":["nic_model = nic.connect(\n","    compiled_decoder,\n","    encoder_model=None,\n","    image_shape=(299, 299, 3)\n",")\n","tf.keras.utils.plot_model(nic_model,\n","                          \"nic.png\",\n","                          show_shapes=True,\n","                          show_dtype=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iK2jtMJJYLCk"},"source":["nic_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLrXNh6lXkPP"},"source":["image_paths = [\n","    os.path.join(path_to_images, image_name)\n","    for image_name in os.listdir(path_to_images)\n","]\n","image_paths"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nux2QIkWST32"},"source":["captions = list(nic.generate_captions_from_paths(\n","    image_paths,\n","    nic_model,\n","    data_dir,\n","    batch_size=32,\n","    caption_limit=100\n","))\n","captions"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rn8_nddmCU2e"},"source":["Let's view one of the images and the caption generated for it.  \n","Pick an image by specifying its index (`image_index`) in the list of paths.  "]},{"cell_type":"code","metadata":{"id":"QvNXLllVDD3M"},"source":["image_index = 0\n","assert 0 <= image_index < len(image_paths)\n","image_path = image_paths[image_index]\n","image_path"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qvbStjutCajU"},"source":["Image.open(image_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LxE0ldai0On4"},"source":["captions[image_index]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_LPH7xW6DTZm"},"source":[""],"execution_count":null,"outputs":[]}]}